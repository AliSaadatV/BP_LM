{"cells":[{"cell_type":"markdown","metadata":{"id":"vmtxQUfhqnhI"},"source":["# General Notebook on fine-tuning branch point prediction using any of MultiMolecule models\n","\n","Any RNA model can be selected from the [MultiMolecule](https://multimolecule.danling.org/models/) website. Simple change the `MULTIMOLECULE_MODEL` variable in the cell below, and the the two cells under the tokenizer \"Load the desired model and tokenizer\" section."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1734033365101,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"yIvmRvnZWrQV"},"outputs":[],"source":["# GLOBAL VARIABLES\n","WORKING_DIRECTORY = '/content/drive/MyDrive/epfl_ml_project'\n","DATASET_PATH = 'data/fresh_dataset.txt'\n","MODEL_MAX_INPUT_SIZE = 1024\n","MULTIMOLECULE_MODEL = \"ernierna\"\n","SAMPLE_N_DATAPOINTS = 20000 # Sample a small subset of data for testing purposes. Set to None if training on full dataset\n","SEED = 32"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2532,"status":"ok","timestamp":1734033367631,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"1cCX_QQAJuHn"},"outputs":[],"source":["%%capture\n","!pip install datasets evaluate multimolecule==0.0.5"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1734033367631,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"o-zSl7dlWxi5"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import (\n","     DataCollatorForTokenClassification,\n","     TrainingArguments,\n","     Trainer\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1734033367631,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"NFiA6C79XBZp","outputId":"0d4782bb-3e50-4a9a-e7f1-06dc4c38b6f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1504,"status":"ok","timestamp":1734033369130,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"YBJNtW_XdceS","outputId":"091bf526-62b6-4638-9568-55c076326905"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/epfl_ml_project\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change working directory to Project folder, you may change this as needed\n","%cd {WORKING_DIRECTORY}\n","\n","from BP_LM.scripts.data_preprocessing import *\n","from BP_LM.scripts.trainer_datasets_creation import *\n","from BP_LM.scripts.compute_metrics import *"]},{"cell_type":"markdown","metadata":{"id":"UboTTVLipicm"},"source":["## Load the desired model and tokenizer"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1734033369436,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"Rfq4DHsTphQG","outputId":"3c7fe82a-07b9-42c5-d688-0ebe86ad1f3a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of ErnieRnaForTokenPrediction were not initialized from the model checkpoint at multimolecule/ernierna and are newly initialized: ['token_head.decoder.bias', 'token_head.decoder.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Change this import depending on the model\n","from multimolecule import RnaTokenizer, ErnieRnaForTokenPrediction, ErnieRnaConfig\n","\n","tokenizer = RnaTokenizer.from_pretrained(f'multimolecule/{MULTIMOLECULE_MODEL}')\n","# Change line below depending on what model we want\n","config = ErnieRnaConfig()\n","config.problem_type = \"single_label_classification\"\n","config.num_labels = 2\n","model = ErnieRnaForTokenPrediction.from_pretrained(f'multimolecule/{MULTIMOLECULE_MODEL}', config=config)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"cX6ZggyrTQUH","executionInfo":{"status":"ok","timestamp":1734033369436,"user_tz":-60,"elapsed":2,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"}}},"outputs":[],"source":["# Set up the collator\n","data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"VieEp7NAqC8i"},"source":["## Create dataset objects for training"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18217,"status":"ok","timestamp":1734033387651,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"vY-AjLcPUpAX","outputId":"6ffc73af-7a9d-4f20-f3d9-f403b8e0fae5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chromosomes in train set: {'chr1', 'chr5', 'chr13', 'chrY', 'chrX', 'chr3', 'chr4', 'chr21', 'chr2', 'chr15', 'chr22', 'chr16', 'chr14', 'chr18', 'chr6', 'chr7', 'chr17', 'chr12', 'chr19', 'chr20'}\n","Chromosomes in validation set: {'chr9', 'chr10'}\n","Chromosomes in test set: {'chr11', 'chr8'}\n","\n","Total data points: 2000\n","Train set contains 1663 data points (83.15%)\n","Validation set contains 156 data points (7.80%)\n","Test set contains 181 data points (9.05%)\n"]}],"source":["# Load dataset\n","df = pd.read_csv(DATASET_PATH, sep='\\t')\n","\n","train_dataset, val_dataset, test_dataset = create_dataset(df, tokenizer, model, MODEL_MAX_INPUT_SIZE, SEED, SAMPLE_N_DATAPOINTS)"]},{"cell_type":"markdown","metadata":{"id":"QXeJRMtaqai-"},"source":["## Train model"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1734033387651,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"NXPqBqyhbFcY"},"outputs":[],"source":["# Do not save to W&B\n","import os\n","os.environ[\"WANDB_MODE\"] = \"disabled\""]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1734033387651,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"I6zO7lLZI9wF"},"outputs":[],"source":["# Define model training parameters\n","batch_size = 16\n","\n","args = TrainingArguments(\n","    f\"multimolecule-{MULTIMOLECULE_MODEL}-finetuned-secondary-structure\",\n","    eval_strategy=\"steps\",\n","    eval_steps=1000,\n","    save_strategy=\"steps\",\n","    save_steps=10000,\n","    learning_rate=3e-4,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    optim = \"adamw_torch\",\n","    weight_decay=0.001,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"F1\",\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":308879,"status":"ok","timestamp":1734033696528,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"MOEm66ctT8dN","outputId":"c34104be-0679-4743-a339-7dac629b9f91"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-1f8e7890bbfe>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [312/312 05:06, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=312, training_loss=0.013283839592566857, metrics={'train_runtime': 308.2708, 'train_samples_per_second': 16.184, 'train_steps_per_second': 1.012, 'total_flos': 2630452641008184.0, 'train_loss': 0.013283839592566857, 'epoch': 3.0})"]},"metadata":{},"execution_count":22}],"source":["metrics = lambda x: compute_metrics(x, \"test_metrics\")\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=metrics,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":6,"status":"error","timestamp":1734033696528,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"Gp9J0L-2GEfd","outputId":"e37fe0f0-9e10-43ea-8e36-4433858b85b9"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'AutoModelForTokenClassification' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-019b49c8f442>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"multimolecule-{MULTIMOLECULE_MODEL}-finetuned-secondary-structure/checkpoint-777\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#make sure you are loading the right checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"multimolecule-{MULTIMOLECULE_MODEL}-finetuned-secondary-structure/checkpoint-777\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorForTokenClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'AutoModelForTokenClassification' is not defined"]}],"source":["trained_model = AutoModelForTokenClassification.from_pretrained(f\"multimolecule-{MULTIMOLECULE_MODEL}-finetuned-secondary-structure/checkpoint-777\") #make sure you are loading the right checkpoint\n","tokenizer = AutoTokenizer.from_pretrained(f\"multimolecule-{MULTIMOLECULE_MODEL}-finetuned-secondary-structure/checkpoint-777\")\n","data_collator = DataCollatorForTokenClassification(tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1734033696529,"user":{"displayName":"Timothy Tran","userId":"17145493925401055495"},"user_tz":-60},"id":"4c3ejbs-JHsE"},"outputs":[],"source":["metric = lambda x: compute_metrics_test(x, \"test_metrics\", 0.001895)\n","\n","testing_args = TrainingArguments(\n","    output_dir='/results',\n","    per_device_eval_batch_size=batch_size,\n","    do_eval=True,\n","    no_cuda=False,\n",")\n","\n","tester = Trainer(\n","    model=trained_model,\n","    args=testing_args,\n","    eval_dataset=test_dataset,\n","    compute_metrics=metric,\n","    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n",")\n","\n","metrics = tester.evaluate()\n","\n","print(\"Evaluation Metrics:\")\n","for key, value in metrics.items():\n","    print(f\"{key}:Â {value}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":0}